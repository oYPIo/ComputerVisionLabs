{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: center; margin: 0;\"> Міністерство освіти і науки України </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> Національний технічний університет України </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> «Київський політехнічний інститут імені Ігоря Сікорського» </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> «Інститут прикладного системного аналізу» </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> Кафедра математичних методів системного аналізу </p>\n",
    "<br>\n",
    "\n",
    "## <p style=\"text-align: center; margin: 0;\"> Звіт </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> про виконання лабораторної роботи №2 </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> з дисципліни </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> «Розпізнавання образів» </p>\n",
    "<br>\n",
    "\n",
    "### <p style=\"text-align: right; margin: 0;\"> Виконали: студенти ІV курсу &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> групи  КА-76  &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Панасюк Я.І. &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> та групи  КА-76  &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Іванов С. &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Перевірила: &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&ensp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Дідковська М.В. &emsp;&emsp;</p>\n",
    "<br>\n",
    "\n",
    "### <p style=\"text-align: center; margin: 0;\"> Київ – 2020 </p>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завдання"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кожен учасник або учасниця команди спершу обирає дескриптор (один із розглянутих у лекціях або ж знайдений окремо) та предмет на прикладі якого відбуватиметься дослідження. Враховуючи що вас багато, будь ласка обирайте унікальніші предмети за улюблену чашку/телефон/мишку. Маючи те і інше напоготові кожен учасник бригади має зняти не менше сотні фото предмета, варіюючи його розміщення та ракурс в кадрі, освітлення, наявність візуальних перешкод, зашакаленість зображення, фокусну віддаль та тремтіння рук. Сотня фото обраного предмету на однаковій сцені з однаковою якістю зйомки, але з різних ракурсів на жаль не підійде, постарайтесь наполегливо варіювати сцени і умови зйомки. До цих фото варто додати невелику підбірку зображень, що не містять предмет, або ж містять предмет візуально подібний до вашого, штук 20 повинно вистачити, якщо залишиться натхнення можна й більше. Після чого ми нарешті дійшли до цікавого, а саме до дослідження:\n",
    "Вам потрібно згенерувати обраний дескриптор для обраного предмета, після чого з його допомогою розпізнати об’єкт на всій тестовій вибірці збираючи при цьому такі метрики: відносна кількість правильно суміщених ознак, похибка локалізації (відстань між реальним розміщенням предмета в кадрі та розпізнаним) та відносний час обробки фото в залежності від розміру зображення. Метрики мають зберегтись у файлику для подальших досліджень. \n",
    "Наступним кроком ви обмінюєтесь об’єктом з колегою, і уже маючи готову збиралку метрик, обчислюєте їх для предмета вашого сусіда, таким чином у вас збирається 9 наборів даних, по три на дескриптор. \n",
    "Самою ж ідеєю лаби є дослідити розбіжності у роботі ваших дескрипторів та виконати порівняльний аналіз їх поведінки, сформулювати висновки з викладками і прикладами так аби було зрозуміло вам та, сподіваюсь, усім вашим колегам. Таким чином кінцевим результатом буде від вас гуглдок з описом виняткових особливостей, сильних та слабких сторін дескриптора і обгрунтуванням чому вони поводяться саме так.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Хід роботи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вибірки об'єктів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2 \n",
    "\n",
    "#DUCK_DS\n",
    "duck_train_pth = glob.glob(\"duck_ds/train/*.jpg\")\n",
    "duck_test_pth = glob.glob(\"duck_ds/test/*.jpg\")\n",
    "duck_ds_train = [cv2.imread(_) for _ in duck_train_pth]\n",
    "duck_ds_test = [cv2.imread(_) for _ in duck_test_pth]\n",
    "reduced_duck_ds_train = [cv2.resize(cv2.imread(_), (0,0), fx=0.5, fy=0.5) for _ in duck_train_pth]\n",
    "reduced_duck_ds_test = [cv2.resize(cv2.imread(_), (0,0), fx=0.5, fy=0.5) for _ in duck_test_pth]\n",
    "\n",
    "#CUP_DS\n",
    "cup_train_pth = glob.glob(\"cup_ds/train/*.jpg\")\n",
    "cup_test_pth = glob.glob(\"cup_ds/test/*.jpg\")\n",
    "cup_ds_train = [cv2.imread(_) for _ in cup_train_pth]\n",
    "cup_ds_test = [cv2.imread(_) for _ in cup_test_pth]\n",
    "reduced_cup_ds_train = [cv2.resize(cv2.imread(_), (0,0), fx=0.5, fy=0.5) for _ in cup_train_pth]\n",
    "reduced_cup_ds_test = [cv2.resize(cv2.imread(_), (0,0), fx=0.5, fy=0.5) for _ in cup_test_pth]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дескриптори"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORB (Oriented FAST and Rotated BRIEF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import time\n",
    "    \n",
    "def ORB_descript(query_img, train_img, show_final_img=False):    \n",
    "    # Read the query image as query_img and train image as train_img\n",
    "    # This query image is what you need to find in train image \n",
    "    # Convert it to grayscale \n",
    "    query_img_bw = cv2.cvtColor(query_img,cv2.COLOR_BGR2GRAY) \n",
    "    train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY) \n",
    "   \n",
    "    # Initialize the ORB detector algorithm \n",
    "    orb = cv2.ORB_create() \n",
    "   \n",
    "    t_start = time.time()\n",
    "\n",
    "    # Now detect the keypoints and compute \n",
    "    # the descriptors for the query image and train image \n",
    "    queryKeypoints, queryDescriptors = orb.detectAndCompute(query_img_bw,None) \n",
    "    trainKeypoints, trainDescriptors = orb.detectAndCompute(train_img_bw,None) \n",
    "  \n",
    "    if(queryDescriptors is None or trainDescriptors is None):\n",
    "        return 0, 966, 0\n",
    "    \n",
    "    # Initialize the Matcher for matching \n",
    "    # the keypoints and then match the keypoints \n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True) \n",
    "    matches = matcher.match(queryDescriptors,trainDescriptors) \n",
    "\n",
    "    t_end = time.time()\n",
    "    # Metrics\n",
    "    # the relative processing time of the image depending on the image size \n",
    "    rel_time = t_end - t_start\n",
    "    \n",
    "    # Sort them in the order of their distance\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    \n",
    "    if(show_final_img):\n",
    "        # draw the matches to the final image \n",
    "        # containing both the images the drawMatches() \n",
    "        # function takes both images and keypoints \n",
    "        # and outputs the matched query image with \n",
    "        # its train image \n",
    "        final_img = cv2.drawMatches(query_img, queryKeypoints,  \n",
    "        train_img, trainKeypoints, matches[:20],None) \n",
    "   \n",
    "        final_img = cv2.resize(final_img, (1000,650)) \n",
    "  \n",
    "        # Show the final image \n",
    "        cv2.imshow(\"Matches\", final_img) \n",
    "        cv2.waitKey(3000)\n",
    "    \n",
    "    # Metrics\n",
    "    # the relative number of correctly matched features\n",
    "    rel_numb = len(matches)*2 / (len(queryDescriptors) + len(trainDescriptors))    \n",
    "    \n",
    "    # localization inaccuracy\n",
    "    distances = [_.distance for _ in matches]\n",
    "    avr_dist = sum(distances)/len(distances)\n",
    "    \n",
    "    return rel_numb, avr_dist, rel_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BRIEF з використанням детектору CenSurE (або STAR в opencv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import time\n",
    "\n",
    "\n",
    "def BRIEF_descript(query_img, train_img, show_final_img=False):    \n",
    "    # Read the query image as query_img and train image as train_img\n",
    "    # This query image is what you need to find in train image \n",
    "    # Convert it to grayscale \n",
    "    query_img_bw = cv2.cvtColor(query_img,cv2.COLOR_BGR2GRAY) \n",
    "    train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    # Initiate STAR detector\n",
    "    star = cv2.xfeatures2d.StarDetector_create()\n",
    "    # Initiate BRIEF extractor\n",
    "    brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "   \n",
    "    t_start = time.time()\n",
    "\n",
    "    # find the keypoints with STAR\n",
    "    queryKeypoints = star.detect(query_img_bw,None)\n",
    "    trainKeypoints = star.detect(train_img_bw,None)\n",
    "    # compute the descriptors with BRIEF\n",
    "    queryKeypoints, queryDescriptors = brief.compute(query_img_bw, queryKeypoints)\n",
    "    trainKeypoints, trainDescriptors = brief.compute(train_img_bw,  trainKeypoints)\n",
    "    \n",
    "    if(queryDescriptors is None or trainDescriptors is None):\n",
    "        return 0, 966, 0\n",
    "\n",
    "    # Initialize the Matcher for matching \n",
    "    # the keypoints and then match the keypoints \n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True) \n",
    "    matches = matcher.match(queryDescriptors,trainDescriptors) \n",
    "\n",
    "    t_end = time.time()\n",
    "    # Metrics\n",
    "    # the relative processing time of the image depending on the image size \n",
    "    rel_time = t_end - t_start\n",
    "    \n",
    "    # Sort them in the order of their distance\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    \n",
    "    if(show_final_img):\n",
    "        # draw the matches to the final image \n",
    "        # containing both the images the drawMatches() \n",
    "        # function takes both images and keypoints \n",
    "        # and outputs the matched query image with \n",
    "        # its train image  \n",
    "        final_img = cv2.drawMatches(query_img, queryKeypoints,  \n",
    "        train_img, trainKeypoints, matches[:20],None) \n",
    "   \n",
    "        final_img = cv2.resize(final_img, (1000,650)) \n",
    "  \n",
    "        # Show the final image \n",
    "        cv2.imshow(\"Matches\", final_img) \n",
    "        cv2.waitKey(3000)\n",
    "    \n",
    "    # Metrics\n",
    "    # the relative number of correctly matched features\n",
    "    rel_numb = len(matches)*2 / (len(queryDescriptors) + len(trainDescriptors))    \n",
    "    \n",
    "    # localization inaccuracy\n",
    "    distances = [_.distance for _ in matches]\n",
    "    avr_dist = sum(distances)/len(distances)\n",
    "    \n",
    "    return rel_numb, avr_dist, rel_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from pathlib import Path\n",
    "\n",
    "def get_metrics(descriptor, ds_train, ds_test, ds_name, descr_name, plotting_graphs=True):\n",
    "    \"\"\"It creates files with \"the relative number of correctly matched features\",\n",
    "    \"localization inaccuracy\" and \"relative processing time\" metrics\"\"\"\n",
    "    rel_numb_of_correct_mathced_feat=[]\n",
    "    distances=[]\n",
    "    relative_time=[]\n",
    "    \n",
    "    for train_img in ds_train:\n",
    "        distances_to_train_img =[]\n",
    "        rel_numb_for_train_img =[]\n",
    "        time_for_train_img =[]\n",
    "        \n",
    "        for test_img in ds_test:\n",
    "            rel_numb, avr_dist, time = descriptor(train_img, test_img)\n",
    "        \n",
    "            rel_numb_for_train_img.append(rel_numb)\n",
    "            distances_to_train_img.append(avr_dist)\n",
    "            time_for_train_img.append(time)\n",
    "        \n",
    "        rel_numb_of_correct_mathced_feat.append(rel_numb_for_train_img)    \n",
    "        distances.append(distances_to_train_img)\n",
    "        relative_time.append(time_for_train_img)\n",
    "        \n",
    "    # Create directories for output data\n",
    "    Path(f\"{ds_name}/metrics/{descr_name}/data\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"{ds_name}/metrics/{descr_name}/graphs\").mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Data and graphs\")\n",
    "    # write metrics for every train img\n",
    "    for i in range(len(ds_train)):\n",
    "        with open(f\"{ds_name}/metrics/{descr_name}/data/train_img{i}_rel_numb.txt\", \"w\") as file1: \n",
    "            file1.write(\"\\n\".join([str(_) for _ in rel_numb_of_correct_mathced_feat[i]]))\n",
    "        with open(f\"{ds_name}/metrics/{descr_name}/data/train_img{i}_avr_dist.txt\", \"w\") as file2:  \n",
    "            file2.write(\"\\n\".join([str(_) for _ in distances[i]]))\n",
    "        with open(f\"{ds_name}/metrics/{descr_name}/data/train_img{i}_relative_time.txt\", \"w\") as file3:  \n",
    "            file3.write(\"\\n\".join([str(_) for _ in relative_time[i]]))\n",
    "    \n",
    "    if(plotting_graphs):\n",
    "        arr=[_ for _ in range(len(ds_test))]\n",
    "        \n",
    "        for i in range(len(ds_train)):\n",
    "            output_file(f\"{ds_name}/metrics/{descr_name}/graphs/train_img{i}_rel_numb_graph.html\")\n",
    "            p = figure(title=f\"the relative number of correctly matched features from train_img_{i}\" , x_axis_label='test_img_id', y_axis_label='rel numb')\n",
    "            p.line(arr, rel_numb_of_correct_mathced_feat[i], legend_label=\"Temp.\", line_width=2)\n",
    "            show(p)\n",
    "        for i in range(len(ds_train)):\n",
    "            output_file(f\"{ds_name}/metrics/{descr_name}/graphs/train_img{i}_distance_graph.html\")\n",
    "            p = figure(title=f\"Distance to train_img_{i}\" , x_axis_label='test_img_id', y_axis_label='distance')\n",
    "            p.line(arr, distances[i], legend_label=\"Temp.\", line_width=2)\n",
    "            show(p)\n",
    "        for i in range(len(ds_train)):\n",
    "            output_file(f\"{ds_name}/metrics/{descr_name}/graphs/train_img{i}_relative_time_graph.html\")\n",
    "            p = figure(title=f\"Relative time for train_img_{i}\" , x_axis_label='test_img_id', y_axis_label='relative_time')\n",
    "            p.line(arr, relative_time[i], legend_label=\"Temp.\", line_width=2)\n",
    "            show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отримання метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duck_ds + ORB descriptor\n",
    "get_metrics(ORB_descript, duck_ds_train, duck_ds_test, \"duck_ds\", \"ORB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cup_ds + ORB descriptor\n",
    "get_metrics(ORB_descript, cup_ds_train, cup_ds_test, \"cup_ds\", \"ORB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cup_ds + BRIEF descriptor\n",
    "get_metrics(BRIEF_descript, cup_ds_train, cup_ds_test, \"cup_ds\", \"BRIEF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duck_ds + BRIEF descriptor\n",
    "get_metrics(BRIEF_descript, duck_ds_train, duck_ds_test, \"duck_ds\", \"BRIEF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resized duck_ds + ORB descriptor\n",
    "get_metrics(ORB_descript, reduced_duck_ds_train, reduced_duck_ds_test, \"duck_ds\", \"reduced_ORB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resized cup_ds + ORB descriptor\n",
    "get_metrics(ORB_descript, reduced_cup_ds_train, reduced_cup_ds_test, \"cup_ds\", \"reduced_ORB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resized cup_ds + BRIEF descriptor\n",
    "get_metrics(BRIEF_descript, reduced_cup_ds_train, reduced_cup_ds_test, \"cup_ds\", \"reduced_BRIEF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resized duck_ds + BRIEF descriptor\n",
    "get_metrics(BRIEF_descript, reduced_duck_ds_train, reduced_duck_ds_test, \"duck_ds\", \"reduced_BRIEF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результати"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отримані метрики можна побачити у файлах:  \n",
    "\\[Назва датасету\\]\\_\\[Метрики\\]\\_\\[Назва дескриптору, наявність стиснення зображень\\]\\_\\[data\\]\\_\\[Номер тренованого зображення в масиві\\]  \n",
    "Граффіки на основі отриманих даних:  \n",
    "\\[Назва датасету\\]\\_\\[Метрики\\]\\_\\[Назва дескриптору, наявність стиснення зображень\\]\\_\\[graphs\\]\\_\\[Номер тренованого зображення в масиві\\]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Щоб вивести дескпиптор конкретного зображення, введіть дескриптор, назви датасетів та номер тренованого й тестового зображення у масиві.  \n",
    "Наприклад:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_numb, avr_dist  = ORB_descript(duck_ds_train[1], duck_ds_test[40], show_final_img=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аналіз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "З отриманих даних можемо зробити такі висновки:  \n",
    "● Похибка локалізації у ORB виявилась стабільно вищою, за відповідну похибку у BRIEF.  \n",
    "● Натомість, він здебільшого показав кращі показники правильності суміщених ознак.  \n",
    "● ORB також був швидшим за конкурента, хоч варто зауважити, що обидва алгоритми пошуку ознак можна вважати дуже швидкими, адже це бінарні алгоритми, що вирізняються значною перевагою у розрахунковій оптимізації в порівнянні з такими алгоритмами як SIFT та SURF, натомість програючи останнім в точності. Різниця в швидкості тут пов'язана із тим, що SIFT та SURF використовують градієнти областей навколо особливої точки, в той час як бінарні алгоритми описують цю облась двійковим рядком попарного порівняння яскравості пікселів, що прискорює обчислення.  \n",
    "● Стиснення зображень додатково значно пришвидшило час роботи обох алгоритмів, майже не вплинувши на інші показники.    \n",
    "  \n",
    "ORB та BRIEF є прикладами бінарних алгоритмів пошуку особливих точок, тож, як було зазначено вище, вирізняються швидкістю роботи, оптимізацією розрахунків, програючи натомість в якості виявлення ознак. Ідейно, BRIEF має такі проблеми як неоптимальний вибір точок для розрахунку дескриптора і неможливість врахування орієнтації точки при розпізнаванні. Метод ORB покликаний усунути зазначені недоліки і бути покращеним аналогом методу BRIEF. Так, для розрахунку кута використовуються кооридинати центру ваги, а сама орієнтація подається вектором із початком в центральній точці і кінцем в центрі ваги, що розраховується через моменти зображення. Перевагою методу BRIEF є те, що дескриптори мають значну дисперсію та середнє значення близько 0,5, що допомагає із однотонними областями зображень, що зазвичай погано розпізнаються і легко корелюють з іншими. Щоб зберегти цю якість та некорельованість бінарних тестів, яку орієнтовані дескриптори втрачають, ORB використовує пошук серед усіх можливих бінарних тестів, щоб знайти ті, що мають високу дисперсію, середні значення близькі до 0,5 та є некорельованими."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Порівняємо результати роботи обох алгоритмів при оборобці зображень з різними типовими видами спотворень. Для цього спробуємо відтворити тест з [1], п.3.  \n",
    "Для кожного типу спотворення створимо вибірки, що включатимуть:  \n",
    "1) еталонне зображення;  \n",
    "2) спотворене відповідним чином зображення;  \n",
    "3) 7 зображень із об’єктами, схожими на шуканий, із тестової вибірки.  \n",
    "Для оцінки порівнюватимемо відносну кількість правильно суміщених ознак. Очевидно, що в більшості випадків цей параметр повинен бути вищим при порівнянні еталонного та спотвореного зображень. Якщо ж він вищий для зображень, лише схожих на оригінал, які насправді не містять об’єкт, то можемо сказати, що відбулася помилка розпізнавання.  \n",
    "Метрики та графіки із результатами можна переглянути у:  \n",
    "\\[Comparison\\]\\_\\[Назва спотворення\\]\\_\\[Назва_датасету\\]\\_\\[metrics\\]\\_\\[Назва дескриптору\\]\\_\\...  \n",
    "Нумерація тестових зображень на графіках та номери записів в файлах з метриками буде приведена для кожного спотворення нижче. Приведемо також таблиці із порівнянням дескрипторів за відносною кількістю правильно суміщених ознак. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вибірка зі спотворенням «**Кут огляду**», датасет duck_ds  \n",
    "Еталонне зображення – train_5.jpg  \n",
    "Спотворене – IMG_20200923_152957.jpg (0 – номер на графіках та номер запису в файлах з метриками)  \n",
    "«Дублікати»:  \n",
    "duck_ds/test\\IMG_20200923_155050.jpg (1)  \n",
    "duck_ds/test\\IMG_20200923_155152.jpg (2)  \n",
    "duck_ds/test\\IMG_20200923_155201.jpg (3)  \n",
    "duck_ds/test\\IMG_20200923_155211.jpg (4)  \n",
    "duck_ds/test\\IMG_20200923_155303.jpg (5)  \n",
    "duck_ds/test\\IMG_20200923_170128.jpg (6)  \n",
    "duck_ds/test\\IMG_20200923_170137.jpg (7)  \n",
    "Результати:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<body>\n",
    "\n",
    "<h4>Кут огляду</h4>\n",
    "\n",
    "<table style=\"width:60%\">\n",
    "  <tr>\n",
    "    <th>№</th>\n",
    "    <th>BRIEF</th> \n",
    "    <th>ORB</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>0.4143112701252236</td>\n",
    "    <td>0.358</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>0.005190311418685121</td>\n",
    "    <td>0.06296296296296296</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>0.1397129186602871</td>\n",
    "    <td>0.292</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>0.16223585548738922</td>\n",
    "    <td>0.298</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4</td>\n",
    "    <td>0.12015209125475285</td>\n",
    "    <td>0.272</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5</td>\n",
    "    <td>0.15316455696202533</td>\n",
    "    <td>0.22</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6</td>\n",
    "    <td>0.12936507936507938</td>\n",
    "    <td>0.304</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>7</td>\n",
    "    <td>0.17913292043830395</td>\n",
    "    <td>0.26</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вибірка зі спотворенням «**Масштаб-поворот**», датасет duck_ds  \n",
    "Еталонне зображення – train_5.jpg  \n",
    "Спотворене – atrain_1.jpg (0)  \n",
    "«Дублікати»:  \n",
    "duck_ds/test\\IMG_20200923_155050.jpg (1)  \n",
    "duck_ds/test\\IMG_20200923_155152.jpg (2)  \n",
    "duck_ds/test\\IMG_20200923_155201.jpg (3)  \n",
    "duck_ds/test\\IMG_20200923_155211.jpg (4)  \n",
    "duck_ds/test\\IMG_20200923_155303.jpg (5)  \n",
    "duck_ds/test\\IMG_20200923_170128.jpg (6)  \n",
    "duck_ds/test\\IMG_20200923_170137.jpg (7)  \n",
    "Результати:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<body>\n",
    "\n",
    "<h4>Масштаб-поворот</h4>\n",
    "\n",
    "<table style=\"width:60%\">\n",
    "  <tr>\n",
    "    <th>№</th>\n",
    "    <th>BRIEF</th> \n",
    "    <th>ORB</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>0.15425888665325285</td>\n",
    "    <td>0.242</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>0.005190311418685121</td>\n",
    "    <td>0.06296296296296296</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>0.1397129186602871</td>\n",
    "    <td>0.292</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>0.16223585548738922</td>\n",
    "    <td>0.298</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4</td>\n",
    "    <td>0.12015209125475285</td>\n",
    "    <td>0.272</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5</td>\n",
    "    <td>0.15316455696202533</td>\n",
    "    <td>0.22</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6</td>\n",
    "    <td>0.12936507936507938</td>\n",
    "    <td>0.304</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>7</td>\n",
    "    <td>0.17913292043830395</td>\n",
    "    <td>0.26</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вибірка зі спотворенням «**Освітлення**», датасет cup_ds   \n",
    "Еталонне зображення – IMG_3879.JPG  \n",
    "Спотворене – IMG_3880.JPG (0)  \n",
    "«Дублікати»:  \n",
    "cup_ds/test\\IMG_3903.JPG (1)  \n",
    "cup_ds/test\\IMG_3906.JPG (2)  \n",
    "cup_ds/test\\IMG_3914.JPG (3)  \n",
    "cup_ds/test\\IMG_3915.JPG (4)  \n",
    "cup_ds/test\\IMG_3916.JPG (5)  \n",
    "cup_ds/test\\IMG_3917.JPG (6)  \n",
    "cup_ds/test\\IMG_3918.JPG (7)  \n",
    "Результати:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<body>\n",
    "\n",
    "<h4>Освітлення</h4>\n",
    "\n",
    "<table style=\"width:60%\">\n",
    "  <tr>\n",
    "    <th>№</th>\n",
    "    <th>BRIEF</th> \n",
    "    <th>ORB</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>0.5559440559440559</td>\n",
    "    <td>0.506</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>0.13498836307214895</td>\n",
    "    <td>0.222</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>0.22748327328872878</td>\n",
    "    <td>0.218</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>0.0558848433530906</td>\n",
    "    <td>0.098</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4</td>\n",
    "    <td>0.10739299610894941</td>\n",
    "    <td>0.1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5</td>\n",
    "    <td>0.20285969615728328</td>\n",
    "    <td>0.156</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6</td>\n",
    "    <td>0.2037797863599014</td>\n",
    "    <td>0.15</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>7</td>\n",
    "    <td>0.20064987814784727</td>\n",
    "    <td>0.136</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вибірка зі спотворенням «**JPEG-стиснення**», датасет cup_ds  \n",
    "Еталонне зображення – train_1.JPG  \n",
    "Спотворене (стиснення в 0,5 разів) – atrain_1.jpg (0)  \n",
    "«Дублікати»:  \n",
    "cup_ds/test\\IMG_3885.JPG (1)  \n",
    "cup_ds/test\\IMG_3886.JPG (2)  \n",
    "cup_ds/test\\IMG_3905.JPG (3)  \n",
    "cup_ds/test\\IMG_3906.JPG (4)  \n",
    "cup_ds/test\\IMG_3914.JPG (5)  \n",
    "cup_ds/test\\IMG_3916.JPG (6)  \n",
    "cup_ds/test\\IMG_3918.JPG (7)  \n",
    "Результати:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<body>\n",
    "\n",
    "<h4>JPEG-стиснення</h4>\n",
    "\n",
    "<table style=\"width:60%\">\n",
    "  <tr>\n",
    "    <th>№</th>\n",
    "    <th>BRIEF</th> \n",
    "    <th>ORB</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>0.18791946308724833</td>\n",
    "    <td>0.342</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>0.06919642857142858</td>\n",
    "    <td>0.178</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>0.02122059549267972</td>\n",
    "    <td>0.146</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>0.09562563580874874</td>\n",
    "    <td>0.188</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4</td>\n",
    "    <td>0.13821815154038303</td>\n",
    "    <td>0.158</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5</td>\n",
    "    <td>0.09111617312072894</td>\n",
    "    <td>0.132</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6</td>\n",
    "    <td>0.12433155080213903</td>\n",
    "    <td>0.086</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>7</td>\n",
    "    <td>0.12325581395348838</td>\n",
    "    <td>0.118</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Висновки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За результатми нашого невеликого дослідження маємо наступне:  \n",
    "● Спотворення \"масштаб-поворот\" призвело до похибки розпізнавання в обох алгоритмах, кут виявився завеликим для обох бінарних дескрипторів.  \n",
    "● BRIEF виявився трохи кращим при оборобці зображень зі спотворенням кута огляду, освітлення, значно кращим при спотворенні \"Розмиття\".  \n",
    "● ORB краще впорався із JPEG-стисненням зображення.  \n",
    "● В цілому обидва алгоритми показали досить високі результати і майже не мали помилок розпізнавання, окрім спотворення \"масштаб-поворот\", що є слабкістю більшості бінарних алгоритмів в порівнянні з такими методами як SIFT та AKAZE.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Використані джерела"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]  Е.А. Краснобаев, Д.В. Чистобаев, А.Л. Малышев. Сравнение бинарных дескрипторов особых точек\n",
    "изображений в условиях искажений. Компьютерная оптика, 2019, том 43, №3. ВГУ имени П.М. Машерова, Витебск, Беларусь"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
