{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: center; margin: 0;\"> Міністерство освіти і науки України </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> Національний технічний університет України </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> «Київський політехнічний інститут імені Ігоря Сікорського» </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> «Інститут прикладного системного аналізу» </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> Кафедра математичних методів системного аналізу </p>\n",
    "<br>\n",
    "\n",
    "## <p style=\"text-align: center; margin: 0;\"> Звіт </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> про виконання лабораторної роботи №2 </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> з дисципліни </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> «Розпізнавання образів» </p>\n",
    "<br>\n",
    "\n",
    "### <p style=\"text-align: right; margin: 0;\"> Виконали: студенти ІV курсу &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> групи  КА-76  &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Панасюк Я.І. &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> та групи  КА-74  &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Іванов С.І. &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Перевірила: &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&ensp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Дідковська М.В. &emsp;&emsp;</p>\n",
    "<br>\n",
    "\n",
    "### <p style=\"text-align: center; margin: 0;\"> Київ – 2020 </p>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завдання"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для початку реалізувати енкодер та декодер (плеєр) для відеоряду на основі методів оцінки руху. Відповідно вхідним файлом буде відеозапис (наприклад трейлер до Тенет), одним з виходів буде файлик у вашому форматі що містить гіпотетично стиснений відеоряд з наприклад інформації щодо руху кожного третього кадру і два сусідні у повному розмірі (MPEG-7 алгоритми з що ми їх дотично згадували в попередніх лекціях будуть в нагоді). Другим виходом буде власне відтворення відео з вашого файлу. Після того як ви налаштували ваш енкодер і плеєр, йдете до друга по команді що в цей час налаштовував свої енкодер і плеєр на основі іншого алгоритму апроксимації руху і ви починаєте об'єднувати зусилля: користуючись вашими енкодерами ви генеруєте ваші апроксимовані зображення та обчислюєте їх різницю в порівнянні з дійсним зображеннями з оригінального відеоряду, збираючи при цьому візуальні різниці для кожного з методів. Окрім цього слід зібрати метрику швидкодії енкодерів і плеєрів, порівняти отримані результати і залляти їх аналогічним чином в гуглдок. Бонусні бали за опцію datamoshing і запис та відтворення аудіо, підтримку більш ніж одного формату відео, сприйняття стрімів з Youtube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Хід роботи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритми апроксимації руху"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Farneback method opt.flow calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Get our sample video\n",
    "cap = cv2.VideoCapture('walking.avi')\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv2.VideoWriter('Farn_encode.avi',fourcc, 20.0, (frame_width,frame_height))\n",
    "\n",
    "# we will aproximate only even frames, while odd frms won't be change\n",
    "odd_frame = True\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "t_start = time.time()\n",
    "while(cap.isOpened()):\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    # Create an image representing our opt.flow\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)    \n",
    "    frame_flow_rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    cv2.imshow('actual footage', frame2)\n",
    "    cv2.imshow('pure optical flow',frame_flow_rgb)\n",
    "    \n",
    "    # write frame to output video.\n",
    "    if(odd_frame):\n",
    "        out.write(frame2)\n",
    "        odd_frame = False\n",
    "    else:\n",
    "        out.write(frame_flow_rgb)\n",
    "        odd_frame = True\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    # Aaaaand... go to the next frame!\n",
    "    prvs = next\n",
    "\n",
    "t_end = time.time()\n",
    "# time metric\n",
    "Farn_encode_time = t_end - t_start\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Get our sample video\n",
    "cap = cv2.VideoCapture('walking.avi')\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv2.VideoWriter('Farn_decode.avi',fourcc, 20.0, (frame_width,frame_height))\n",
    "\n",
    "# we will aproximate only even frames, while odd frms won't be change\n",
    "odd_frame = True\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "t_start = time.time()\n",
    "while(cap.isOpened()):\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 30, 3, 5, 1.2, 0)\n",
    "    \n",
    "    h, w = flow.shape[:2]\n",
    "    flow = -flow # here we invert the flow in order to get the previous image\n",
    "    flow[:,:,0] += np.arange(w)\n",
    "    flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "\n",
    "    frame_warped = cv2.remap(frame2, flow, None, cv2.INTER_LINEAR)\n",
    "    \n",
    "    cv2.imshow('warped', frame_warped)\n",
    "    \n",
    "    if(odd_frame):\n",
    "        out.write(frame2)\n",
    "        odd_frame = False\n",
    "    else:\n",
    "        out.write(frame_warped)\n",
    "        odd_frame = True\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Aaaaand... go to the next frame!\n",
    "    prvs = next\n",
    "\n",
    "t_end = time.time()\n",
    "# time metric\n",
    "Farn_decode_time = t_end - t_start\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dual TV L1 method opt.flow calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Get our sample video\n",
    "cap = cv2.VideoCapture('walking.avi')\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv2.VideoWriter('Dual_encode.avi',fourcc, 20.0, (frame_width,frame_height))\n",
    "\n",
    "# we will aproximate only even frames, while odd frms won't be change\n",
    "odd_frame = True\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "t_start = time.time()\n",
    "while(cap.isOpened()):\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    optical_flow = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "    flow = optical_flow.calc(prvs, next, None)\n",
    "    \n",
    "    # Create an image representing our opt.flow\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)    \n",
    "    frame_flow_rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    cv2.imshow('actual footage', frame2)\n",
    "    cv2.imshow('pure optical flow',frame_flow_rgb)\n",
    "    \n",
    "    # write frame to output video.\n",
    "    if(odd_frame):\n",
    "        out.write(frame2)\n",
    "        odd_frame = False\n",
    "    else:\n",
    "        out.write(frame_flow_rgb)\n",
    "        odd_frame = True\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    # Aaaaand... go to the next frame!\n",
    "    prvs = next\n",
    "    \n",
    "t_end = time.time()\n",
    "# time metric\n",
    "Dual_encode_time = t_end - t_start\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Get our sample video\n",
    "cap = cv2.VideoCapture('walking.avi')\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv2.VideoWriter('Dual_decode.avi',fourcc, 20.0, (frame_width,frame_height))\n",
    "odd_frame = True\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "t_start = time.time()\n",
    "while(cap.isOpened()):\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    optical_flow = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "    flow = optical_flow.calc(prvs, next, None)\n",
    "    \n",
    "    h, w = flow.shape[:2]\n",
    "    flow = -flow # here we invert the flow in order to get the previous image\n",
    "    flow[:,:,0] += np.arange(w)\n",
    "    flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "\n",
    "    frame_warped = cv2.remap(frame2, flow, None, cv2.INTER_LINEAR)\n",
    "    \n",
    "    cv2.imshow('warped', frame_warped)\n",
    "    \n",
    "    if(odd_frame):\n",
    "        out.write(frame2)\n",
    "        odd_frame = False\n",
    "    else:\n",
    "        out.write(frame_warped)\n",
    "        odd_frame = True\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Aaaaand... go to the next frame!\n",
    "    prvs = next\n",
    "\n",
    "t_end = time.time()\n",
    "# time metric\n",
    "Dual_decode_time = t_end - t_start    \n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Порівняння алгоритмів"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точність"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Швидкість роботи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Farn_encode_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Farn_decode_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dual_encode_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dual_decode_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
