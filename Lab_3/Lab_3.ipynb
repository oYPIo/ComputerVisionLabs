{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: center; margin: 0;\"> Міністерство освіти і науки України </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> Національний технічний університет України </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> «Київський політехнічний інститут імені Ігоря Сікорського» </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> «Інститут прикладного системного аналізу» </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> Кафедра математичних методів системного аналізу </p>\n",
    "<br>\n",
    "\n",
    "## <p style=\"text-align: center; margin: 0;\"> Звіт </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> про виконання лабораторної роботи №2 </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> з дисципліни </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> «Розпізнавання образів» </p>\n",
    "<br>\n",
    "\n",
    "### <p style=\"text-align: right; margin: 0;\"> Виконали: студенти ІV курсу &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> групи  КА-76  &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Панасюк Я.І. &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> та групи  КА-74  &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Іванов С.І. &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Перевірила: &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&ensp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Дідковська М.В. &emsp;&emsp;</p>\n",
    "<br>\n",
    "\n",
    "### <p style=\"text-align: center; margin: 0;\"> Київ – 2020 </p>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завдання"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для початку реалізувати енкодер та декодер (плеєр) для відеоряду на основі методів оцінки руху. Відповідно вхідним файлом буде відеозапис (наприклад трейлер до Тенет), одним з виходів буде файлик у вашому форматі що містить гіпотетично стиснений відеоряд з наприклад інформації щодо руху кожного третього кадру і два сусідні у повному розмірі (MPEG-7 алгоритми з що ми їх дотично згадували в попередніх лекціях будуть в нагоді). Другим виходом буде власне відтворення відео з вашого файлу. Після того як ви налаштували ваш енкодер і плеєр, йдете до друга по команді що в цей час налаштовував свої енкодер і плеєр на основі іншого алгоритму апроксимації руху і ви починаєте об'єднувати зусилля: користуючись вашими енкодерами ви генеруєте ваші апроксимовані зображення та обчислюєте їх різницю в порівнянні з дійсним зображеннями з оригінального відеоряду, збираючи при цьому візуальні різниці для кожного з методів. Окрім цього слід зібрати метрику швидкодії енкодерів і плеєрів, порівняти отримані результати і залляти їх аналогічним чином в гуглдок. Бонусні бали за опцію datamoshing і запис та відтворення аудіо, підтримку більш ніж одного формату відео, сприйняття стрімів з Youtube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Хід роботи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "основне завдання + підтримка більш ніж одного формату відео + відео з фреймів-різниць"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритми апроксимації руху"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Farneback method opt.flow calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Get our sample video\n",
    "cap = cv2.VideoCapture('walking.avi')\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv2.VideoWriter('Farn_encode.avi',fourcc, 20.0, (frame_width,frame_height))\n",
    "\n",
    "# we will aproximate only even frames, while odd frms won't be change\n",
    "odd_frame = True\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "t_start = time.time()\n",
    "while(cap.isOpened()):\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret: break\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    # Create an image representing our opt.flow\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)    \n",
    "    frame_flow_rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('actual footage', frame2)\n",
    "    cv2.imshow('pure optical flow',frame_flow_rgb)\n",
    "    \n",
    "    # write frame to output video.\n",
    "    if(odd_frame):\n",
    "        out.write(frame2)\n",
    "        odd_frame = False\n",
    "    else:\n",
    "        out.write(frame_flow_rgb)\n",
    "        odd_frame = True\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    # Aaaaand... go to the next frame!\n",
    "    prvs = next\n",
    "\n",
    "t_end = time.time()\n",
    "# time metric\n",
    "Farn_encode_time = t_end - t_start\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Get our sample video\n",
    "cap = cv2.VideoCapture('walking.avi')\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv2.VideoWriter('Farn_decode.avi',fourcc, 20.0, (frame_width,frame_height))\n",
    "\n",
    "# we will aproximate only even frames, while odd frms won't be change\n",
    "odd_frame = True\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "t_start = time.time()\n",
    "while(cap.isOpened()):\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret: break\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 30, 3, 5, 1.2, 0)\n",
    "    \n",
    "    h, w = flow.shape[:2]\n",
    "    flow = -flow # here we invert the flow in order to get the previous image\n",
    "    flow[:,:,0] += np.arange(w)\n",
    "    flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "\n",
    "    frame_warped = cv2.remap(frame2, flow, None, cv2.INTER_LINEAR)\n",
    "    \n",
    "    cv2.imshow('warped', frame_warped)\n",
    "    \n",
    "    if(odd_frame):\n",
    "        out.write(frame2)\n",
    "        odd_frame = False\n",
    "    else:\n",
    "        out.write(frame_warped)\n",
    "        odd_frame = True\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Aaaaand... go to the next frame!\n",
    "    prvs = next\n",
    "\n",
    "t_end = time.time()\n",
    "# time metric\n",
    "Farn_decode_time = t_end - t_start\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dual TV L1 method opt.flow calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Get our sample video\n",
    "cap = cv2.VideoCapture('walking.avi')\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv2.VideoWriter('Dual_encode.avi',fourcc, 20.0, (frame_width,frame_height))\n",
    "\n",
    "# we will aproximate only even frames, while odd frms won't be change\n",
    "odd_frame = True\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "t_start = time.time()\n",
    "while(cap.isOpened()):\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret: break\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    optical_flow = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "    flow = optical_flow.calc(prvs, next, None)\n",
    "    \n",
    "    # Create an image representing our opt.flow\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)    \n",
    "    frame_flow_rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    cv2.imshow('actual footage', frame2)\n",
    "    cv2.imshow('pure optical flow',frame_flow_rgb)\n",
    "    \n",
    "    # write frame to output video.\n",
    "    if(odd_frame):\n",
    "        out.write(frame2)\n",
    "        odd_frame = False\n",
    "    else:\n",
    "        out.write(frame_flow_rgb)\n",
    "        odd_frame = True\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    # Aaaaand... go to the next frame!\n",
    "    prvs = next\n",
    "    \n",
    "t_end = time.time()\n",
    "# time metric\n",
    "Dual_encode_time = t_end - t_start\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Get our sample video\n",
    "cap = cv2.VideoCapture('walking.avi')\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv2.VideoWriter('Dual_decode.avi',fourcc, 20.0, (frame_width,frame_height))\n",
    "odd_frame = True\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "t_start = time.time()\n",
    "while(cap.isOpened()):\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret: break\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    optical_flow = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "    flow = optical_flow.calc(prvs, next, None)\n",
    "    \n",
    "    h, w = flow.shape[:2]\n",
    "    flow = -flow # here we invert the flow in order to get the previous image\n",
    "    flow[:,:,0] += np.arange(w)\n",
    "    flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "\n",
    "    frame_warped = cv2.remap(frame2, flow, None, cv2.INTER_LINEAR)\n",
    "    \n",
    "    cv2.imshow('warped', frame_warped)\n",
    "    \n",
    "    if(odd_frame):\n",
    "        out.write(frame2)\n",
    "        odd_frame = False\n",
    "    else:\n",
    "        out.write(frame_warped)\n",
    "        odd_frame = True\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Aaaaand... go to the next frame!\n",
    "    prvs = next\n",
    "\n",
    "t_end = time.time()\n",
    "# time metric\n",
    "Dual_decode_time = t_end - t_start    \n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Порівняння алгоритмів"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точність\n",
    "\n",
    "Створимо відео на якому зображено різницю між двома файлами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_diff(v1,v2):\n",
    "    # Get our sample video\n",
    "    origin = cv2.VideoCapture(v1)\n",
    "    aprox = cv2.VideoCapture(v2)\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    frame_width = int(origin.get(3))\n",
    "    frame_height = int(origin.get(4))\n",
    "    out = cv2.VideoWriter(f'diff_({v1})_&&_({v2}).avi',fourcc, 20.0, (frame_width,frame_height))\n",
    "    \n",
    "    while(origin.isOpened() and aprox.isOpened()):\n",
    "        ret1, frame1 = origin.read()\n",
    "        ret2, frame2 = aprox.read() \n",
    "        if (ret1 == False or ret2 == False): break\n",
    "        \n",
    "        # compute difference\n",
    "        difference = cv2.subtract(frame1, frame2)\n",
    "         \n",
    "        # color the mask red\n",
    "        Conv_hsv_Gray = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)\n",
    "        ret, mask = cv2.threshold(Conv_hsv_Gray, 0, 255,cv2.THRESH_BINARY_INV |cv2.THRESH_OTSU)\n",
    "        difference[mask != 255] = [0, 0, 255]\n",
    "        out.write(difference)\n",
    "            \n",
    "    origin.release()\n",
    "    aprox.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_diff('walking', 'Farn_decode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_diff('walking', 'Dual_decode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_diff('Dual_decode', 'Farn_decode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Швидкість роботи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225.7192506790161"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Farn_encode_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223.70712995529175"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Farn_decode_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2637.011543273926"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dual_encode_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2381.591493368149"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dual_decode_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аналіз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "З отриманих візуальних різниць та метрик швидкодії можемо зробити такі висновки:\n",
    "- Farneback показав трохи менші візуальні різниці, в порівнянні з методом Dual TV-L1, хоча різниця для тестових відео виявилась несуттєвою;\n",
    "- Dual TV-L1 був значно повільнішим в роботі, для деяких тестових відео метрики швидкодії цього методу в кілька разів перевищували відповідні метрики для методу Farneback.\n",
    "\n",
    "Варто зазначити, що для значного поліпшення швидкодії цих методів можна подавати на вхід зображення (кадри) меншого розміру, наприклад зменшувати їх вдвічі по обох осях. В нашому прикладі це було наочно видно при подачі на вхід відео із меншою роздільною здатністю і, відповідно, розміром кадрів.\n",
    "\n",
    "Обидва алгоритми, Dual TV-L1 та Farneback є алгоритмами для обчислення щільного (dense) optical flow. Методи апроксимації руху за допомогою Optical Flow демонструють значно кращу точність результатів апроксимації в порівнянні, наприклад, з block matching методами [1]. Вони також демонструють більшу стійкість при роботі із зображеннями зі спотвореннями, так, optical flow методи здатні витримувати поворот об’єкта до 4⁰ та деформацію зсуву до 6 відсотків без втрат в точності апроксимації.\n",
    "\n",
    "Dense optical flow алгоритми, зокрема, працюють із щільним оптичним потоком, тобто вираховують зсув не окремих, а усіх точок зображення, на відміну від sparce або вибіркового оптичного потоку. Вибірковий потік зазвичай вираховується швидше, за щільний, проте деякі методи маєть не таку й значну різницю в швидкодіх та деякі задачі потребують знаходження оптичного потоку для усіх точок зображення.\n",
    "\t\n",
    "Обидва методи працюють з показником інтенсивності точки, тобто яскравості або кольору (для кольорових зображень). Метод Dual TV-L1 ґрунтується на модифікації функціоналу, описаного в методі Horn-Schunck для врахування можливих розривів або переривчастості в оптичному потоці шляхом зміни квадратичних коефіцієнтів [4], і може бути представлений як мінімізація функціоналу, що є сумою повної варіації (Total Variance) векторного поля u та норми"
   ]
  },
  {
   "attachments": {
    "photo_2020-11-06_11-44-23.jpg": {
     "image/jpeg": "/9j/4AAQSkZJRgABAQEAeAB4AAD/2wCEAAgICAgJCAkKCgkNDgwODRMREBARExwUFhQWFBwrGx8bGx8bKyYuJSMlLiZENS8vNUROQj5CTl9VVV93cXecnNEBCAgICAkICQoKCQ0ODA4NExEQEBETHBQWFBYUHCsbHxsbHxsrJi4lIyUuJkQ1Ly81RE5CPkJOX1VVX3dxd5yc0f/CABEIADkBLgMBIgACEQEDEQH/xAAbAAEAAwEBAQEAAAAAAAAAAAAABAUGAwcCAf/aAAgBAQAAAAD38AKW6AAAAAB+eeeiAAAAFPWzb2rm9yghXuTs7iwrZSRTZi41Cluo8jP9rqrmdqhc4Gz+MzNu+7S+aei19LQWrtpsprKbNabBayfc5bZeW7KJkbP5v5uhhc402quZJ5t6RX/ff6457SfkmiuekSm7X0bvwq4dn25cOlwARMdVekSQAAAAB+flTa/YAAAAAAAAAB//xAAWAQEBAQAAAAAAAAAAAAAAAAAAAQL/2gAIAQIQAAAABKABLKk1LFixSVKllRQAAA//xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAgBAxAAAAAAAAEqWKhUsolSkoAAAP/EACgQAAICAgECBQQDAAAAAAAAAAMEAgUBBgAQEQcSFBU2EzA1UBYhQP/aAAgBAQABCAD7bewU6j4UWP0mc/1nmmDBbxuLhj/XfWuaapdseHuLgNHKz4ezPmzTrl+W7DaqRGlVmAtrhYB12l/23XbZzGip4S1KkDy0ZIrWusDtdrsa2NBiJbXalFynLVONO1yjDXLpoqdTYtBUJIywCSbeWVwHBuSsGIbABONRtOw203xABd38LZNBnpF8+Nhkj0VbWYKzCHAXc837dMa+eMhXTYDy4so1iM2eL4PEA8MSxnOM4xVWRW/WAYoHjWFLXuH5v3dpSqpsTh7XazORDvncdi89OBWO47woXwwnkump5nouZ/xOo7tZew0byKysPVBzLnimUkteAgJcEABEEd9+EteP0grzUYISpbkuzI11UfaYMZfpABo7M7d1sJYFtJ2+ivvERzLFet5djnedqnJEiWOZZ9WT5cny+7a3tKN9ylGVwL1vkjTo6bYZAf2VqvRO+tH5fLjc7GPk9JSlu4uX2YRlLA8SLc2sy2FTsq22fhCctmytbFV0owHaYwgae7DiO901iNVgY/Ey8GJD5hsXk1DPfVqbHRqlpWT/AF2g01MseLCz9YcNurarNU9Uyb1DTVNBVA6lKkoFJVdUPXZh+4bpqCHS3AVmrfAKuFMKCgiL1temw2wuyomxiETr1CakCzThQuI6i7TwRFIagITcRWbiD63JqMZ2NZzj1ehYpTVexGMcYxj2KnN3kSy160ZZCVbCbGNjk50VTAqRogmFwMBmA069MqmUyX6B2qrKysNdwS/trGxtagT9ZlUWVAWKIoWWKOnVLBkFPXnXw401ryjCNDVps/ZtrhGrUyy5Tj9w2+8tuDZezqlu81XYaImvlr9EYAWBTEca4FwwCHGqUYFCrQXXCquFcP7/AP/EAEMQAAIBBAADBAQHDAsAAAAAAAECAwAEERIFEyEQMUFRFGFxciMyYnOBsbMGFSAiMEJQU1RVg6ElM0BDRVJgY3STsv/aAAgBAQAJPwD8ndiO4lKKiEHvkzqCe4E4/Q0SSm64q7wOy5xHbfBxkf2yJJPR4mk0d9Q2PCuG226WvpDwG4YNgLsQDpQUStHz52PURxA4x7znsRZGh/HeLxkRerKPJiO6nDRSxq6N5qwyD+AcNFayFPfIwteNqsn/AG/j1jeK3kdc+aqTXD4Jl4jpFzpJjCkczjIBwr1wrhSRIhd3N/J0C/wKthbyyRhzDsW0z4ZIHZjmQWssi580UkVjLRqx+kU+oklWJOhOXbuHTs15T2U0x89kdFH11wWwSazuDBNHLeuHBHshPQ1wqxUTJJIzw3TysiJ4kGNO3HJFkJvXsXK9kmTBJy5BgjDahsdfUeyAIy26XMEgP9ZGTo30qa13E0CdfKSVUPYm77LHFGDjeSRtUX6SadHmCjcoNVJ9QNHBoKLu0m5M+O49AyuPU4OaxzZoQ7YGBk9n+I8Rhif5pDu9XEl1LftBBbxOVBVY8mTGAOgyWrwtbHT3DzKGLXkWruhJ1w8eXNOWzJP9oa/UYHu5OK4hxxF8Et7e1eMewvETXEOOuueqz29skZ94pEp7Pj399BbihhEQKo9QGK/ZJv8AwaIDvaRmN/8AJIACrUCLmByOLL/xzjQ/OtVzIj3d5FGNTrokJM0re1guKnMubgwWsDuRGBZhVkbuOMu9RCOSSyvAUByBpslAE8lPqq0sh/SNsRrcOfH5ura3QAdOVK0mfbsi1+67j7WOjrZX2LS/8lb+6lNMUlvgORkfEt06RdPXner2dZbrisXC7LLnIKEQtJ7zHJNWvMsrZINGfO10JjqeWfAj1iv3Wn2pqCCTv25srR49mqvVpZEniA3DTuADyI/KOgqkDLYPQfTSAcNsbv0Z5/10VwdHcf7aGv2m0+3SpSkRhlvLrU6syRkIiewsaLGxf7rG9EycjkqjAafI3rKu3FEjZvNaOF+9yO6g9N2YVjU2liW97MlHut17OFWc0/g8kKOw+lhXC7SGcLrzY4UR8H1gUNyU9GuI842jJ2Vh60NcNtJZ8AB3hVnCg5xk1Y29o1ydHkijSMRgjBkIGMkeFLrFDGsaDyVRgfgd0BnvZP4fxOxcvJbyIo8yy4oYdIUVh5ECrVI5blxJMR3uQMAtUCSlGDruAdGwRkeurW3tnYd6RBc+0DFTpcube5WNhHystNsfFmoYKRqG9oFAkxTJKmDjDJ1BPYnwC2M0Rb5TSIwH8qt0mgkxujDO2DmhgVw22YmQyEtEpJfz9vSuI2kMECAQRPaGTksBjdfhFG4/NyKT4A2CxbZ/PEhbsB2uJubJ72oT6lqNZI5FKujjIZT3giraJrbTQwsgKajuGtRZfnW5VcgdI5VY/wAhUNvMksMMFqpGxSNQS+c+ZanEMsTxyW7BekckJ2SuHRMchmhlCzKrjyrhFolxGp1eOFFcew1j0u8m5soHUIAAiID8kCk0mhgCuMg4P5KXlQB0TbUt1c4XotdYbeFOHwP5lDvLV3dJxaGWdcJK4CTo5ESKgOpBoKLjlIZcdwfHXH6DiSSNxhkcBlI9YNRJHGowqIoVQPIAVDOInlSXAuZtg0eNcPtlcYpNYokVFXyVRgf6A//EACQRAAIABAUFAQAAAAAAAAAAAAABEBExQSBCUWGBAjAyQHGR/9oACAECAQE/AMN+84VXEx1lBZnvI12lB0mOvI/LpLTJGUsnsLL9NCpbFRL9NcF0429n/8QAIxEAAQQBAgcBAAAAAAAAAAAAAQAQMUERIIECMDJAQlFhof/aAAgBAwEBPwDTXPpQd8IQx8VY3YSuHpz8VFW1ljJXtQEZxqv8U4LgYHe//9k="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![photo_2020-11-06_11-44-23.jpg](attachment:photo_2020-11-06_11-44-23.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в той час як метод Farneback [3] ґрунтується на ідеї апроксимації зміни інтенсивності в околі точки за допомогою квадратичної форми"
   ]
  },
  {
   "attachments": {
    "photo_2020-11-06_11-44-23%20%282%29.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![photo_2020-11-06_11-44-23%20%282%29.jpg](attachment:photo_2020-11-06_11-44-23%20%282%29.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Варто відзначити, що обидва методи добре спрацьовують при невеликих зсувах і мають проблеми при зсувах, більших за 1 піксель. В такому випадку рекомендується використовувати multi-scaling: будувати «піраміду» з зображень із меншою роздільною здатністю, ніж оригінал. Алгоритм спочатку проходить по найнижчому рівню піраміди (із найменшою роздільною здатністю) і результат використовується як початкові точки на наступних рівнях [4].\n",
    "\n",
    "При роботі із зображеннями із спотвореннями метод Farneback демонструє гірші [4] показники середньої кутової похибки (Average Angle Error) та середньої похибки кінцевої точки (Average End-Point Error) на датасетах Middlebury [5][6] та Sintel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Використані джерела"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]   Zhi Liu, Jianwen Luo \"Performance comparison of optical flow and block matching methods in shearing and rotating models\", Proc. SPIE 10139, Medical Imaging 2017: Ultrasonic Imaging and Tomography, 1013917 (13 March 2017); https://doi.org/10.1117/12.2253689\n",
    "\n",
    "[2]   Josh Harguess, Chris Barngrover, and Amin Rahimi \"An analysis of optical flow on real and simulated data with degradations\", Proc. SPIE 10199, Geospatial Informatics, Fusion, and Motion Video Analytics VII, 1019905 (1 May 2017); https://doi.org/10.1117/12.2265850\n",
    "\n",
    "[3]   G. Farneback, \"Fast and accurate motion estimation using orientation tensors and parametric motion models,\" Proceedings 15th International Conference on Pattern Recognition. ICPR-2000, Barcelona, Spain, 2000, pp. 135-139 vol.1, doi: 10.1109/ICPR.2000.905291.\n",
    "\n",
    "[4]   J. S. Perez, E. Meinhardt-Llopis, and G. Facciolo. “TV-L1optical flow estimation”, IPOL Journal, 3:137–150, 2013\n",
    "\n",
    "[5] https://vision.middlebury.edu/flow/eval/results/results-a1.php\n",
    "\n",
    "[6] https://vision.middlebury.edu/flow/eval/results/results-e1.php\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
