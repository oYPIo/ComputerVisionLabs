{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: center; margin: 0;\"> Міністерство освіти і науки України </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> Національний технічний університет України </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> «Київський політехнічний інститут імені Ігоря Сікорського» </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> «Інститут прикладного системного аналізу» </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> Кафедра математичних методів системного аналізу </p>\n",
    "<br>\n",
    "\n",
    "## <p style=\"text-align: center; margin: 0;\"> Звіт </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> про виконання лабораторної роботи №2 </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> з дисципліни </p>\n",
    "### <p style=\"text-align: center; margin: 0;\"> «Розпізнавання образів» </p>\n",
    "<br>\n",
    "\n",
    "### <p style=\"text-align: right; margin: 0;\"> Виконали: студенти ІV курсу &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> групи  КА-76  &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Панасюк Я.І. &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> та групи  КА-74  &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Іванов С.І. &emsp;&emsp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Перевірила: &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&ensp;</p>\n",
    "### <p style=\"text-align: right; margin: 0;\"> Дідковська М.В. &emsp;&emsp;</p>\n",
    "<br>\n",
    "\n",
    "### <p style=\"text-align: center; margin: 0;\"> Київ – 2020 </p>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завдання"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для початку реалізувати енкодер та декодер (плеєр) для відеоряду на основі методів оцінки руху. Відповідно вхідним файлом буде відеозапис (наприклад трейлер до Тенет), одним з виходів буде файлик у вашому форматі що містить гіпотетично стиснений відеоряд з наприклад інформації щодо руху кожного третього кадру і два сусідні у повному розмірі (MPEG-7 алгоритми з що ми їх дотично згадували в попередніх лекціях будуть в нагоді). Другим виходом буде власне відтворення відео з вашого файлу. Після того як ви налаштували ваш енкодер і плеєр, йдете до друга по команді що в цей час налаштовував свої енкодер і плеєр на основі іншого алгоритму апроксимації руху і ви починаєте об'єднувати зусилля: користуючись вашими енкодерами ви генеруєте ваші апроксимовані зображення та обчислюєте їх різницю в порівнянні з дійсним зображеннями з оригінального відеоряду, збираючи при цьому візуальні різниці для кожного з методів. Окрім цього слід зібрати метрику швидкодії енкодерів і плеєрів, порівняти отримані результати і залляти їх аналогічним чином в гуглдок. Бонусні бали за опцію datamoshing і запис та відтворення аудіо, підтримку більш ніж одного формату відео, сприйняття стрімів з Youtube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Хід роботи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритми апроксимації руху"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Get our sample video\n",
    "cap = cv2.VideoCapture('walking.avi')\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Uncomment the next line for Farneback method opt.flow calculation\n",
    "    #flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    # Uncomment the next 2 lines for Dual TV L1 method opt.flow calculation\n",
    "    #optical_flow = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "    #flow = optical_flow.calc(prvs, next, None)\n",
    "    \n",
    "    # Create an image representing our opt.flow\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    frame_flow_rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    cv2.imshow('actual footage', frame2)\n",
    "    cv2.imshow('pure optical flow',frame_flow_rgb)\n",
    "    # Warp the next frame with calculated optical flow\n",
    "    # to create an approximated \"previous frame\"\n",
    "    h, w = flow.shape[:2]\n",
    "    flow = -flow # here we invert the flow in order to get the previous image\n",
    "    flow[:,:,0] += np.arange(w)\n",
    "    flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "\n",
    "    frame_warped = cv2.remap(frame2, flow, None, cv2.INTER_LINEAR)\n",
    "    cv2.imshow('warped', frame_warped)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    # Aaaaand... go to the next frame!\n",
    "    prvs = next\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "cap = cv2.VideoCapture('walking.avi')\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "# Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if (ret == True):\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Frame',frame)\n",
    "\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Break the loop\n",
    "    else: \n",
    "        break\n",
    "\n",
    "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "# Define the fps to be equal to 10. Also frame size is passed.\n",
    "\n",
    "out = cv2.VideoWriter('outpy.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    " \n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('original.avi',fourcc, 20.0, (640,480))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Farneback method opt.flow calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Get our sample video\n",
    "cap = cv2.VideoCapture('walking.avi')\n",
    "\n",
    "# Added\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Added: Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('encode.avi',fourcc, 20.0, (frame_width,frame_height))\n",
    "equal_frame = True\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    # Create an image representing our opt.flow\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    frame_flow_rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    cv2.imshow('actual footage', frame2)\n",
    "    cv2.imshow('pure optical flow',frame_flow_rgb)\n",
    "    # Warp the next frame with calculated optical flow\n",
    "    # to create an approximated \"previous frame\"\n",
    "    h, w = flow.shape[:2]\n",
    "    flow = -flow # here we invert the flow in order to get the previous image\n",
    "    flow[:,:,0] += np.arange(w)\n",
    "    flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "\n",
    "    frame_warped = cv2.remap(frame2, flow, None, cv2.INTER_LINEAR)\n",
    "    cv2.imshow('warped', frame_warped)\n",
    "\n",
    "    # Added: write frame to output video.\n",
    "    if(equal_frame):\n",
    "        out.write(frame2)\n",
    "        equal_frame = False\n",
    "    else:\n",
    "        out.write(frame_flow_rgb)\n",
    "        equal_frame = True\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    # Aaaaand... go to the next frame!\n",
    "    prvs = next\n",
    "    \n",
    "# Added\n",
    "cap.release()\n",
    "\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Get our sample video\n",
    "cap = cv2.VideoCapture('encode.avi')\n",
    "\n",
    "# Added\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Added: Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('decode.avi',fourcc, 20.0, (frame_width,frame_height))\n",
    "equal_frame = True\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    # Create an image representing our opt.flow\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    frame_flow_rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    cv2.imshow('actual footage', frame2)\n",
    "    cv2.imshow('pure optical flow',frame_flow_rgb)\n",
    "    # Warp the next frame with calculated optical flow\n",
    "    # to create an approximated \"previous frame\"\n",
    "    h, w = flow.shape[:2]\n",
    "    flow = -flow # here we invert the flow in order to get the previous image\n",
    "    flow[:,:,0] += np.arange(w)\n",
    "    flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "\n",
    "    frame_warped = cv2.remap(frame2, flow, None, cv2.INTER_LINEAR)\n",
    "    cv2.imshow('warped', frame_warped)\n",
    "\n",
    "    # Added: write frame to output video. Problems might be in frame's color\n",
    "    if(equal_frame):\n",
    "        out.write(frame2)\n",
    "        equal_frame = False\n",
    "    else:\n",
    "        out.write(frame_warped)\n",
    "        equal_frame = True\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    # Aaaaand... go to the next frame!\n",
    "    prvs = next\n",
    "    \n",
    "# Added\n",
    "cap.release()\n",
    "\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dual TV L1 method opt.flow calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Get our sample video\n",
    "cap = cv2.VideoCapture('walking.avi')\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Uncomment the next 2 lines for Dual TV L1 method opt.flow calculation\n",
    "    optical_flow = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "    flow = optical_flow.calc(prvs, next, None)\n",
    "\n",
    "    # Create an image representing our opt.flow\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    frame_flow_rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    cv2.imshow('actual footage', frame2)\n",
    "    cv2.imshow('pure optical flow',frame_flow_rgb)\n",
    "    # Warp the next frame with calculated optical flow\n",
    "    # to create an approximated \"previous frame\"\n",
    "    h, w = flow.shape[:2]\n",
    "    flow = -flow # here we invert the flow in order to get the previous image\n",
    "    flow[:,:,0] += np.arange(w)\n",
    "    flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "\n",
    "    frame_warped = cv2.remap(frame2, flow, None, cv2.INTER_LINEAR)\n",
    "    cv2.imshow('warped', frame_warped)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    # Aaaaand... go to the next frame!\n",
    "    prvs = next\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
